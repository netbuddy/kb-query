import os
import chainlit as cl
from llama_index.core import (
    Settings,
    StorageContext,
    load_index_from_storage
)
from llama_index.storage.docstore.redis import RedisDocumentStore
from llama_index.storage.index_store.redis import RedisIndexStore
from llama_index.vector_stores.milvus import MilvusVectorStore
from llama_index.llms.openai import OpenAI
import redis
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# Redis é…ç½®
REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_PASSWORD = None

# Milvus é…ç½®
MILVUS_HOST = "localhost"
MILVUS_PORT = 19530

# OpenAI é…ç½®
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.base_url = os.getenv("OPENAI_BASE_URL")

# è®¾ç½® LlamaIndex é»˜è®¤ LLM
Settings.llm = OpenAI(model="gpt-3.5-turbo-0125")

# åˆå§‹åŒ– Redis å®¢æˆ·ç«¯
redis_client = redis.Redis(
    host=REDIS_HOST,
    port=REDIS_PORT,
    password=REDIS_PASSWORD,
    decode_responses=True
)

@cl.step(type="tool", name="åˆå§‹åŒ–å­˜å‚¨ä¸Šä¸‹æ–‡")
async def get_storage_context(index_name: str):
    """åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡"""
    doc_store = RedisDocumentStore.from_host_and_port(
        host=REDIS_HOST,
        port=REDIS_PORT,
        namespace=index_name
    )
    
    index_store = RedisIndexStore.from_host_and_port(
        host=REDIS_HOST,
        port=REDIS_PORT,
        namespace=index_name
    )
    
    vector_store = MilvusVectorStore(
        uri=f"tcp://{MILVUS_HOST}:{MILVUS_PORT}",
        collection_name=index_name,
        dim=1536,
        overwrite=False
    )
    
    return StorageContext.from_defaults(
        docstore=doc_store,
        index_store=index_store,
        vector_store=vector_store
    )

@cl.step(type="tool", name="åŠ è½½ç´¢å¼•")
async def load_index(storage_context):
    """åŠ è½½ç´¢å¼•"""
    return load_index_from_storage(storage_context)

@cl.step(type="tool", name="åˆ›å»ºæŸ¥è¯¢å¼•æ“")
async def create_query_engine(index):
    """åˆ›å»ºæŸ¥è¯¢å¼•æ“"""
    return index.as_query_engine(
        streaming=True,
        similarity_top_k=3
    )

@cl.step(type="tool", name="æ£€ç´¢ç›¸å…³æ–‡æ¡£")
async def retrieve_documents(query_engine, query_text: str):
    """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
    step = cl.context.current_step
    step.input = f"ç”¨æˆ·é—®é¢˜: {query_text}"
    
    # æ‰§è¡ŒæŸ¥è¯¢è·å–å“åº”
    response = await cl.make_async(query_engine.query)(query_text)
    
    # è·å–æºæ–‡æ¡£ä¿¡æ¯
    source_info = []
    if hasattr(response, 'source_nodes'):
        for node in response.source_nodes:
            source_info.append({
                'score': round(node.score, 3) if hasattr(node, 'score') else None,
                'text': node.node.text[:200] + "..."  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
            })
    
    # æ˜¾ç¤ºè¾“å‡º
    output_text = "æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£:\n"
    for idx, source in enumerate(source_info, 1):
        output_text += f"\n{idx}. ç›¸å…³åº¦: {source['score']}\næ–‡æœ¬: {source['text']}\n"
    
    step.output = output_text
    return response, source_info

@cl.step(type="tool", name="ç”Ÿæˆå›ç­”")
async def generate_answer(response):
    """ç”Ÿæˆ AI å›ç­”"""
    step = cl.context.current_step
    step.input = "åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆå›ç­”"
    
    # è·å–å®Œæ•´å“åº”æ–‡æœ¬
    response_text = ""
    if hasattr(response, 'response_gen'):
        for text in response.response_gen:
            response_text += text
    else:
        response_text = str(response)
    
    step.output = f"AIå›ç­”: {response_text}"
    return response_text

@cl.on_chat_start
async def start():
    """èŠå¤©å¯åŠ¨æ—¶çš„å¤„ç†å‡½æ•°"""
    # ä» Redis è·å–ç´¢å¼•åˆ—è¡¨
    index_names = redis_client.smembers("llama_index:namespaces")
    
    if not index_names:
        await cl.Message(
            content="æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„çŸ¥è¯†åº“ï¼Œè¯·ç¡®ä¿å·²ç»åˆ›å»ºäº†ç´¢å¼•ã€‚"
        ).send()
        return
    
    # åˆ›å»ºçŸ¥è¯†åº“é€‰æ‹©åŠ¨ä½œåˆ—è¡¨
    actions = [
        cl.Action(
            name=index_name,
            value=index_name,
            label=f"ğŸ“š {index_name}"
        ) for index_name in index_names
    ]
    
    # åˆ›å»ºé€‰æ‹©ç•Œé¢
    res = await cl.AskActionMessage(
        content="è¯·é€‰æ‹©è¦æŸ¥è¯¢çš„çŸ¥è¯†åº“ï¼š",
        actions=actions,
    ).send()
    
    if res:
        selected_index = res.get("value")
        try:
            # åŠ è½½é€‰å®šçš„ç´¢å¼•
            storage_context = await get_storage_context(selected_index)
            index = await load_index(storage_context)
            query_engine = await create_query_engine(index)
            
            # å­˜å‚¨åˆ°ç”¨æˆ·ä¼šè¯
            cl.user_session.set("query_engine", query_engine)
            
            await cl.Message(
                content=f"å·²é€‰æ‹©çŸ¥è¯†åº“ï¼š{selected_index}ï¼Œæ‚¨å¯ä»¥å¼€å§‹æé—®äº†ã€‚"
            ).send()
        except Exception as e:
            await cl.Message(
                content=f"åŠ è½½çŸ¥è¯†åº“æ—¶å‡ºé”™ï¼š{str(e)}"
            ).send()
    else:
        await cl.Message(
            content="æœªé€‰æ‹©çŸ¥è¯†åº“ï¼Œè¯·é‡æ–°å¼€å§‹å¯¹è¯ã€‚"
        ).send()

@cl.on_message
async def main(message: cl.Message):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    query_engine = cl.user_session.get("query_engine")
    if not query_engine:
        await cl.Message(
            content="è¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“ã€‚"
        ).send()
        return

    try:
        # # æ­¥éª¤1: æ£€ç´¢ç›¸å…³æ–‡æ¡£
        response, source_info = await retrieve_documents(query_engine, message.content)
        
        # æ­¥éª¤2: ç”Ÿæˆå›ç­”
        response_text = await generate_answer(response)

        # response_text = "abcdef"
        # source_info = []
        # source_info.append({
        #     'score': 0.9,
        #     'text': "123456"
        # })
        # source_info.append({
        #     'score': 0.8,
        #     'text': "7890"
        # })

        # æ„å»ºæºæ–‡æ¡£å±•ç¤ºæ–‡æœ¬
        elements = []
        element_refs = []  # å­˜å‚¨å…ƒç´ å¼•ç”¨æ–‡æœ¬

        for idx, source in enumerate(source_info, 1):
            # æ ¼å¼åŒ–ç›¸å…³åº¦ä¸ºç™¾åˆ†æ¯”
            element_name = f"å‚è€ƒæ–‡æ¡£_{idx}(ç›¸å…³åº¦ï¼š{source['score']})"
            
            elements.append(
                cl.Text(
                    name=element_name,
                    content=source['text'],  # åªæ˜¾ç¤ºæ–‡æ¡£å†…å®¹
                    display="side"
                )
            )
            element_refs.append(element_name)  # æ·»åŠ å…ƒç´ å¼•ç”¨

        # åˆ›å»ºæµå¼æ¶ˆæ¯å¹¶é€å­—ç¬¦æ˜¾ç¤º
        msg = cl.Message(content="", elements=elements)
        for token in response_text:
            await msg.stream_token(token)

        # æ·»åŠ å…ƒç´ å¼•ç”¨
        await msg.stream_token("\n\nå‚è€ƒæ–‡æ¡£ï¼š")
        for ref in element_refs:
            await msg.stream_token(f"\n{ref}")

        await msg.send()
            
    except Exception as e:
        await cl.Message(
            content=f"æŸ¥è¯¢å‡ºé”™ï¼š{str(e)}"
        ).send() 